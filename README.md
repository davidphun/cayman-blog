# Data Science Roadmap
Statement: The purpose of this repo is just to keep track of the progression of my own curriculum.
## There are few notes that needed to consider before taking a look at this repo:
1. Supervised ML Algorithms:
   - Logistic Regression (almost complete)
    * Define hypothesis and cost function of Logistic Regression
    * Mathematical derivation of the generalized cost function of Logistic Regression
    * Optimization for model parameters via Gradient Descent algorithm & Newton's method
    * Introduce Regularization to the objective function of Logistic Regression
    * Visualization of Decision Boundary when Logistic Regression is applied
    * Probabilistic Logistic Regression (todo)
   - Multiple Linear Regression (almost complete)
    * Understanding the covariance matrix (done)
    * Multiple Linear Regression with Dummies Exercise (done)
    * Probabilistic Linear Regression (done)
        * Difference between Frequentist approach & Bayesian approach
        * Likelihood & Maximum a Posteriori & Posterior Predictive declaration of Linear Regression
        * Examples of tunning parameters of posterior distribution via Metropolis sampling & NUTS sampling
   - Gaussian Process (done)
    * Introduction (done)
    * Gaussian Process definition & mathematical derivation (done)
    * Implementation
        * Define prior & posterior predictive for GP (done)
        * Prediction with noise-free & noise assumption (done)
        * Examine the affect of hyper parameters of kernel function & noise parameter of data (done)
        * Implementation of GP in higher dimension (done)
        * Libraries of GP implementation (todo)
2. Statistical Concepts
    - Likelihood
      * Maximum Likelihood Estimation (MLE) (done)
      * Fisher Information & Cramer-Rao Inequality (done)
      * Newton-Raphson Method & Fisher Scoring Method (done)
      * Expectation-Maximization (EM) algorithm (done)
      * Generalized Likelihood Ratio (todo)
    - Monte Carlo Sampling
      * Resampling & Bootstrap method (todo)
      * Metropolis Hastings Algorithm (done)
      * Gibbs Sampling Algorithm (done)
    - Bayesian Statistics (done)
      * Normal Linear Model
      * Priors & Conjugacy
      * Bayesian Model Comparison
3. Unsupervised ML Algorithms: (todo)
4. Reinforcement Learning: (todo)
5. Clustering Algorithms: (todo)
6. Deep Learning: (todo)
7. More advanced topics: (todo)
